{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "# Ratings of Yelp Reviews Prediction\n",
    "#### Yichen Shi, Yanran Wang, Kai Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "## Part 1: Background & Data Overview\n",
    "* **Thesis Statement:**\n",
    "    * **Background**  Yelp is an Internet company founded in 2004 to “help people find great local businesses” by providing a platform for users to write reviews of businesses. \n",
    "\n",
    "    * **Goal:**  1. find out what makes a review positive or negative based on the review and a small set of attributes; 2. propose a prediction model to predict the ratings of reviews based on the text and said attributes.\n",
    "\n",
    "* **Dataset:**\n",
    "    * In the dataset collected in recent years, stars, name, text, date, city, categories, longitude and latitude were recorded for 1,546,379 reviews, with no missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "## Part 2: Data Processing\n",
    "    \n",
    "### 2.1 Text Processing\n",
    "* Text Processing\n",
    "    * Remove punctuations\n",
    "    * Lowercase every word\n",
    "    * Extract the word stem\n",
    "    * Remove stopwords\n",
    "* Generate corpus from the whole train data and vectorize all texts that comprise a large sparse matrix.\n",
    "* Dimension Reduction\n",
    "    * Chi-square test that selects K most informative columns\n",
    "* Convert following features into numpy arrays and merge into the original sparse matrix\n",
    "    * The number of specific punctuations and expressions: ‘?’, ’!’, ’:)’, ’:D’, etc.\n",
    "    * The number of all caps: ‘GOOD’,’NOT’,etc.\n",
    "    * Text length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "Apprently, texts play an important role in determining whether a review is positive or negative. To discuss the answer of our Goal 1, we plotted word clouds consists of words in texts can mostly indicate a positive or negative review: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidePrompt": true
   },
   "source": [
    "<img style=\"float: center;\" src=\"https://github.com/tuierjiewang/628-Module2/blob/master/Image/WordCloud.png?raw=true\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Other feathers \n",
    "\n",
    "* Categories:\n",
    "    \n",
    "    Intuitively, some categories have great influence on the ratings of stars.\n",
    "    \n",
    "    Thus, we transform each category name from phrase into word by removing the white spaces, and special symbols, then lowercased every word. Then we use the same method we applied on texts to transfer these categories into vectors.\n",
    "\n",
    "* Date:\n",
    "\n",
    "    The intuitive assumption before we study time effects is whether Yelp users’ attitudes towards restaurants would change or not as social trends developed. Particularly whether people become more picky about food or not as time passed by. Thus, we transformed the data into time series. Since the data is not collected evenly during a month, we compute the average rating per month and plot it against date. \n",
    "    \n",
    "    From graph **[fig.1] Time Effect**, There seems a downward trend from 2005 to 2009 and then becomes flat-tailed, but this does not mean people in the past like dine out more than nowadays. If we look at the number of earlier users in Yelp we could found the number is just small portion compared with nowadays, so the possible reason is people has less access to Internet in the past and ones who wrote reviews are more likely to give positive ratings, while for others who do not like the restaurants, they had less motivation to visit Yelp. This also suggests the data collection in the past would be more biased in response. As the number of people using Yelp increased, we notice the proportion of negative ratings increased and the average rating more balanced and getting close to the 3 stars as well. Then we scaled *year*, *month* and *day* separately for later usage.\n",
    "    \n",
    "\n",
    "* Longitude & Latitude: \n",
    "\n",
    "    City, longitude and latitude all stand for position information, we paied our attention on longitude and latitude, and split the data into groups equally spaced with respect to longitude and latitude.Then we could compute the average rating of each group horizontally, from east to west, and vertically, from north to south. In this case, since we assume large cities and small cities equally lies in each area, the related effect would be balanced.\n",
    "\n",
    "    From the result **[fig. 2] Geographical Effect**, there seems a positive relationship between rating and longitude, and a negative relationship with latitude. So we scaled these two features for later usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src=\"https://github.com/tuierjiewang/628-Module2/blob/master/Image/effect.png?raw=true\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Prediction Model\n",
    "\n",
    "We applied different models ( KNN, Lasso, Ridge, SVM, RandomForest, NeuralNetwork, LogisticRegression and NaiveBayes) to do the prediction. By comparing precision of different models on the test set, we get the table below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "INFO | KNN |Lasso | Ridge| SVM|Random Forest|Neural Network|Logistic|Naive Bayes|\n",
    "------------ | -------------| ------------- |-------------  | ------| ------| -------------| -------------| -------------| -------------\n",
    "Just Text| 0.95623       |0.92309   | 0.82218     |0.62696 | 0.86966    | 0.66243 | 0.76966 | 0.90876\n",
    "Text and Category   | 0.94235 | 0.92242| 0.80475| 0.62682| 0.85546| 0.65644 | 0.76656| 0.90123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "As can be seen in the table above, SVMs has the smallest RMSE. Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection. There are many advantages of using support vector machines. For example, it is effective in high dimensional spaces and still effective in cases where number of dimensions is greater than the number of samples.Besides, it uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\n",
    "\n",
    "We used sklearn in python to apply these methods. For our svm model, we choosed RBF kernel, and used cross-validation and grid-search to find our best c and g (the hyperparamter).\n",
    "\n",
    "Also, Text+Category gives us  more accuracy on the test set than just Text and this is not surprising since some categatied do affect the reviews. For example, \"Fast Food\" is usually cheap and not well servised, thus it may lead to lower stars.\n",
    "\n",
    "We also tried to combine other variables, like longitude, latitude and time altogether, but there seems no prove to the accuracy of prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "## Part 4: Interpretable Model\n",
    "Although we have fitted several models to do the prediction and choose SVM, who has the smallest RMSE as the best model, we cannot interpret our model well. So we have come up witha fairly simple method to perform such predictions. It works to some extend, but not as good as we want it to be.  All we do is computing the average rating of all the words and categaries in all the reviews. Then we can retrieve the corresponding rating of each word in a new review and average allthe ratings. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Features Processing\n",
    "\n",
    "We first extracted year, month, day, longitude and latitude and scale them. For texts, we calculated average stars  for each words and then got average score for each review. We do the same thing on categories. Finally, we used these 7 variables to do a simple regression on stars.\n",
    "\n",
    "\n",
    "### 4.2 Model Fitting\n",
    "Our initial model is $$\\text{Stars} = 3.741 + 1.108723*\\text{TextScore}+ 0.042362*\\text{CategoryScore}+ 0.001122*\\text{longitude}- 0.001569*\\text{latitude}+ 0.000914*\\text{Year}+ 0.000569*\\text{Month}+ 0.000629*\\text{Day} $$\n",
    "Since only TextScore and CategoryScore are significant, here is our final Interpretable Model:\n",
    "$$\\text{Stars} = 3.741 + 1.108723*\\text{TextScore}+ 0.043080*\\text{CategoryScore}$$\n",
    "\n",
    "From the model, we can see that texts and categories are the most important effect in rating, which agreed with our pretiction model. Intuitively, we could easily recognize whether a review is positive or negative by just looking at its text. And from the qq plot below, the normality is satisfied to some extend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src=\"https://github.com/tuierjiewang/628-Module2/blob/master/Image/QQ.png?raw=true\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "## Part 4: Conclusion\n",
    "### 4.1 Strengths\n",
    "   * **Prediction Model:** Our prediction model has been chosen for its greatest strength, which is high accuracy and small RMSE, about 0.62 given by Kaggle.\n",
    "   * **Interpretable Model:** Compared to other complex model, this model is more intuitive and easy to interpret.\n",
    "   \n",
    "### 4.2 Weaknesses\n",
    "   * **Prediction Model:** We've tried much more advanved methods such as Neural Network, however failed to get the final results due to time and device limit. Also, there're more useful ways we could've tried to improve our text processing to get more effective clean data.\n",
    "   * **Interpretable Model:** This model has poor accuracy since it is supposed to be simple.\n",
    "   \n",
    "### 4.3 Contribution\n",
    "\n",
    "| Name         | Contibution                                                                     |\n",
    "|--------------|---------------------------------------------------------------------------------|\n",
    "| Yichen Shi   | Analyzed data and fitted two models.                                            |\n",
    "| Yanran Wang  | Analyzed data, made GitHub repo, notebook, and slides for presentation.         |\n",
    "| Kai Wang     | Analyzed and explored features. Processed data.                                 |"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
